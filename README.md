# Intelligent Grants Search — Prototype

Small prototype for harvesting and normalizing Ukrainian grant / opportunity data.

This repository contains connectors, normalization logic, and sample data collected from CKAN (data.gov.ua) and the NRFU WordPress site. The project uses Poetry for dependency and virtual environment management.

## Quick setup (Windows, PowerShell)

1. Install Poetry (if not already):
   - Follow https://python-poetry.org/docs/#installation

2. Install project dependencies and create virtualenv:
   - Open PowerShell in the project root (`d:\nulp\diploma`) and run:
     ```powershell
     poetry install
     ```

3. Activate the virtualenv (optional):
   ```powershell
   poetry shell
   ```

## Run connectors

- CKAN connector (search example):
  ```powershell
  poetry run python backend\connectors\ckan_connector.py --q "грант" --rows 20
  ```
  Output: `data/ckan_raw.json` and `data/ckan_sample_normalized.json` (sample paths)

- NRFU scraper (WP REST fallback and HTML scraping):
  ```powershell
  poetry run python backend\connectors\nrfu_scraper.py
  ```
  Output: `data/nrfu_contest_sample_wp.json` (and other sample files)

## Run tests

Run the unit tests (pytest is configured as a dev dependency):

```powershell
poetry run pytest -q
```

Status (last run in this workspace): 3 tests passed.

## Ingest and rerun connectors

After running the connectors and producing normalized sample JSON files in `data/`, you can ingest them into a local SQLite staging DB and re-run connectors easily.

- Ingest normalized samples into SQLite (default DB: `data/opportunities.db`):
  ```powershell
  poetry run python backend\ingest\ingest_to_sqlite.py --db data\opportunities.db --data-dir data --pattern "*_sample_*.json"
  ```

- Re-run all connectors (wrapper):
  ```powershell
  poetry run python backend\run_connectors.py
  ```

The ingestion script creates a table `staging_opportunities` and stores provenance fields (raw_path, normalized_path, fetched_at). The rerun wrapper calls both CKAN and NRFU harvesters in sequence and prints results to console.

## Project layout (important files)

- `backend/connectors/ckan_connector.py` — CKAN connector + normalize function (unit-testable mapping)
- `backend/connectors/nrfu_scraper.py` — NRFU WP REST + HTML scraping connector
- `data/` — saved raw and normalized JSON samples
- `tests/test_ckan_normalize.py` — pytest for the CKAN normalizer
- `pyproject.toml` — Poetry project + dependencies
- `docs/harvest_steps.md` — reproduction steps and notes

## Assumptions

- You have network access to the target APIs (data.gov.ua and NRFU). If behind a proxy, set environment variables (HTTP_PROXY/HTTPS_PROXY) or configure Poetry accordingly.
- Connectors defer heavy imports for testability; install dependencies via Poetry before running networked scripts.

## Recommended next steps

1. Add a CI workflow (GitHub Actions) to run `poetry install` and `pytest` on push/PR.
2. Add a `README` badge for tests/CI once CI is in place.
3. Add an ingestion script to load normalized JSON into a staging DB (or CSV) with provenance fields.
4. Add more unit tests for NRFU normalizer and edge cases (missing dates, language variants).

If you'd like, I can implement any of the recommended next steps now — tell me which one to do first.

---
Generated by the development assistant to capture the repository's current run and test instructions.
# Grant Harvester prototypes

Small prototype connectors and documentation for harvesting Ukrainian grant data sources (CKAN + NRFU).

Run instructions (recommended: use Poetry):

```powershell
# create virtual env & install via poetry
poetry install

# run CKAN connector
python backend\connectors\ckan_connector.py --q "грант" --rows 20

# run NRFU scraper
python backend\connectors\nrfu_scraper.py
```

Notes:
- The code is intentionally small and easy to extend. For production add robust logging, better error handling, and storage/DB wiring.
